{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### <font color='pink'> *Rozpoznawanie obrazów (2025)* </font>\n",
    "\n",
    "\n",
    "## LAB 3: Klasyfikatory: Gaussian Naive Bayes, LDA, QDA, KNN, SVM\n",
    "\n",
    "<font color='orange'> Prowadząca: dr inż. Urszula Libal </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1) Dane gaussowskie"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ZAD.1. Wygeneruj 100 punktów z dwuwymiarowego rozkładu normalnego, a następnie je zwizualizuj."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Generowanie danych\n",
    "np.random.seed(42)  # Ustalony seed dla powtarzalności\n",
    "\n",
    "# Klasa 1\n",
    "mean1 = [1, 2]\n",
    "cov1 = [[1, 0], [0, 3]]\n",
    "points1 = np.random.multivariate_normal(mean1, cov1, 100)\n",
    "\n",
    "# Klasa 2\n",
    "mean2 = [-1, -1]\n",
    "cov2 = [[4, 0.2], [0.2, 1]]\n",
    "points2 = np.random.multivariate_normal(mean2, cov2, 100)\n",
    "\n",
    "# Łączenie danych i etykiet klas\n",
    "dane = np.vstack((points1, points2))  # Połączenie macierzy\n",
    "klasa = np.hstack((np.ones(100), np.zeros(100)))  # Klasa 1 -> 1, Klasa 2 -> 0\n",
    "\n",
    "\n",
    "# Rysowanie punktów\n",
    "plt.scatter(dane[klasa == 1, 0], dane[klasa == 1, 1], color='red', label='Klasa 1')\n",
    "plt.scatter(dane[klasa == 0, 0], dane[klasa == 0, 1], color='blue', label='Klasa 2')\n",
    "plt.xlabel(\"Cecha 1\")\n",
    "plt.ylabel(\"Cecha 2\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.title(\"Wizualizacja punktów na płaszczyźnie\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ZAD.2. Poniższy kod dzieli dane na 90%:10% na zbiór treningowy i testowy, oraz przeprowadza klasyfikację za pomocą klasyfikatorów LDA, SVM i KNN (K=5).\n",
    "- Sprawrawdź działanie algorytmów: porównaj dokładności klasyfikacji, macierze pomyłek i kształt obszarów decyzyjnych.\n",
    "- Dopisz kod umożliwiający klasyfikację za pomocą NaiveBayes oraz QDA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis as QDA\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "import seaborn as sns\n",
    "\n",
    "# Podział na zbiór uczący (90%) i testowy (10%)\n",
    "X_train, X_test, y_train, y_test = train_test_split(dane, klasa, test_size=0.1, random_state=42)\n",
    "\n",
    "# Klasyfikatory\n",
    "classifiers = {\n",
    "    \"LDA\": LDA(),\n",
    "    \"SVM\": SVC(kernel='linear', probability=True),\n",
    "    \"KNN\": KNeighborsClassifier(n_neighbors=5)\n",
    "}\n",
    "\n",
    "# Trenowanie i testowanie\n",
    "results = {}\n",
    "for name, model in classifiers.items():\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    \n",
    "    results[name] = {\"accuracy\": acc, \"conf_matrix\": cm}\n",
    "    print(f\"{name} Accuracy: {acc:.4f}\")\n",
    "    print(f\"{name} Confusion Matrix:\\n{cm}\\n\")\n",
    "\n",
    "# Wizualizacja obszarów decyzyjnych\n",
    "def plot_decision_boundary(model, X, y, title):\n",
    "    x_min, x_max = X[:, 0].min() - 1, X[:, 0].max() + 1\n",
    "    y_min, y_max = X[:, 1].min() - 1, X[:, 1].max() + 1\n",
    "    xx, yy = np.meshgrid(np.linspace(x_min, x_max, 100),\n",
    "                         np.linspace(y_min, y_max, 100))\n",
    "    \n",
    "    Z = model.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "    Z = Z.reshape(xx.shape)\n",
    "\n",
    "    plt.scatter(X[y == 1, 0], X[y == 1, 1], color='blue', alpha=0.5, label='klasa 1')\n",
    "    plt.scatter(X[y == 0, 0], X[y == 0, 1], color='red', alpha=0.5, label='klasa 2')\n",
    "    plt.contourf(xx, yy, Z, alpha=0.3)\n",
    "    plt.xlabel(\"Cecha 1\")\n",
    "    plt.ylabel(\"Cecha 2\")\n",
    "    plt.legend()\n",
    "    plt.title(title)\n",
    "    plt.show()\n",
    "\n",
    "for name, model in classifiers.items():\n",
    "    plot_decision_boundary(model, dane, klasa, f\"Obszary decyzyjne - {name}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ZAD.3. Wykorzystaj poprzedni kod i przeprowadź klasyfikację dla podziału na zbiór treningowy i testowy:\n",
    "- 25% treningowy, 75% testowy\n",
    "- 50% treningowy, 50% testowy\n",
    "- 75% treningowy, 25% testowy\n",
    "\n",
    "Co się zmieniło? Jak pojedyncza pomyłka wpłwa na wynik accuracy?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ZAD.4. Sprawdzenie, czy dane pochodzą z rozkładu normalnego. \n",
    "- Które z użytych klasyfikatorów zakładają, że dane w klasach pochodza z rozkładu normalnego?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Podział danych na klasy\n",
    "class_1 = dane[klasa == 1]  # Punkty klasy 1\n",
    "class_2 = dane[klasa == 0]  # Punkty klasy 2\n",
    "\n",
    "# Rysowanie histogramów dla cechy x1\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.hist(class_1[:, 0], bins=15, alpha=0.7, color='blue', label='Klasa 1')\n",
    "plt.hist(class_2[:, 0], bins=15, alpha=0.7, color='red', label='Klasa 2')\n",
    "plt.xlabel(\"Cecha x1\")\n",
    "plt.ylabel(\"Liczność\")\n",
    "plt.title(\"Histogram cechy x1\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "# Rysowanie histogramów dla cechy x2\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.hist(class_1[:, 1], bins=15, alpha=0.7, color='blue', label='Klasa 1')\n",
    "plt.hist(class_2[:, 1], bins=15, alpha=0.7, color='red', label='Klasa 2')\n",
    "plt.xlabel(\"Cecha x2\")\n",
    "plt.ylabel(\"Liczność\")\n",
    "plt.title(\"Histogram cechy x2\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2) Dane Iris"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ZAD. 6. Sprawdź, czy dane Iris w poszczególnych klasach pochodzą z rozkładu normalnego:\n",
    "- Sprawdź wszystkie 4 cechy.\n",
    "- Dobierz odpowiednią liczbę przedziałów histogramów (bins)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ZAD.6  Histogramy poszczególnych cech w klasach\n",
    "# Cecha: 'sepal length (cm)'\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn import datasets\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "iris = datasets.load_iris()\n",
    "iris_df = pd.DataFrame(iris.data, columns=iris.feature_names)\n",
    "\n",
    "sns.histplot(x='sepal length (cm)', data=iris_df, kde=True, hue=iris.target)\n",
    "plt.title('sepal length (cm)')\n",
    "plt.show()\n",
    "\n",
    "# ZAD. Wyrysuj histogramy dla pozostałych cech\n",
    "# Czy możemy założyć, że cechy te mają rozkład normalny?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ZAD.7. Jeśli można założyć rozkład normalny w klasach, zastosuj Gaussian Naive Bayes.\n",
    "- Zbadaj zależność dokładności klasyfikacji od wielkości zbioru uczącego i testowego.\n",
    "- Jaka jest wielkość zbioru testowego w poszczególnych przypadkach?\n",
    "- Wylicz macierz pomyłekdla skrajnych przypadków.\n",
    "- Jaki procent danych powinien zostać umieszony w zbiorze testowym?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ZAD.7 Naive Bayes (zależność dokładności klasyfikacji od wielkości zbioru uczącego i testowego)\n",
    "\n",
    "# Wyrysuj dokładności klasyfikacji (accuracy) \n",
    "# w zależności od wielkości zbioru uczącego (parametr train_size albo test_size).\n",
    "\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn import metrics\n",
    "\n",
    "X, y = load_iris(return_X_y=True)\n",
    "\n",
    "accuracy = []\n",
    "train_part = np.arange(0.05,0.95, 0.02)\n",
    "\n",
    "for tp in train_part:\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=tp, random_state=42)\n",
    "    gnb = GaussianNB()\n",
    "    y_pred = gnb.fit(X_train, y_train).predict(X_test)\n",
    "    accuracy.append(metrics.accuracy_score(y_test, y_pred))\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "print('Train set size =',train_part)\n",
    "print('Accuracy =', np.round(accuracy, 2))\n",
    "\n",
    "plt.plot(train_part,accuracy,label='Gaussian Naive Bayes')\n",
    "plt.axis([0, 1, 0.5, 1.05])\n",
    "plt.xlabel('Train set size [%]')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ZAD.8. Przeprowadź analizę dokładności klasyfikacji w zależności od wielkości zbioru uczącego dla pozostałych klasyfikatorów, tzn. LDA, QDA, KNN, SVM. Wyrysuj wszystkie wykresy na jednym obrazku."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ZAD.9. Wyznacz obszary decyzyjne dla danych Iris dla klasyfikatorów: GNB, LDA, QDA, KNN, SVM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ZAD.9 Obszary decyzyjne (dane Iris) dla dwóch pierszych cech\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.inspection import DecisionBoundaryDisplay\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "iris = load_iris()\n",
    "feature_1, feature_2 = np.meshgrid(\n",
    "    np.linspace(iris.data[:, 0].min(), iris.data[:, 0].max()),\n",
    "    np.linspace(iris.data[:, 1].min(), iris.data[:, 1].max())\n",
    ")\n",
    "grid = np.vstack([feature_1.ravel(), feature_2.ravel()]).T\n",
    "gnb = GaussianNB().fit(iris.data[:, :2], iris.target)\n",
    "y_pred = np.reshape(gnb.predict(grid), feature_1.shape)\n",
    "display = DecisionBoundaryDisplay(xx0=feature_1, xx1=feature_2, response=y_pred)\n",
    "display.plot()\n",
    "display.ax_.scatter(iris.data[:, 0], iris.data[:, 1], c=iris.target, edgecolor=\"black\")\n",
    "plt.title(\"Obszary decyzyjne dla GNB\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3) Dane Moons"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ZAD.10. Przeprowadź klasyfikację dla danych Moons różnymi klasyfikatorami. \n",
    "- Wyrysuj obszary decyzyjne.\n",
    "- Spróbuj użyć także metody Kernel SVM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_moons\n",
    "\n",
    "X, y = make_moons(n_samples=200, noise=0.2, random_state=42)\n",
    "\n",
    "#..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
